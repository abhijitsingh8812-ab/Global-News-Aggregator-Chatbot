{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S_3RANmFXFc",
        "outputId": "059be454-2ae0-4aa4-8789-3579f6c090a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåç Global News Aggregator - Type 'exit' to quit\n",
            "Examples: 'politics news from Germany', 'natural disasters last week', 'vehicle industry news'\n",
            "\n",
            "What news would you like? indian political\n",
            "\n",
            "üì∞ Found 5 articles:\n",
            "\n",
            "1. As Sales Drop, Tesla Makes a Big Gamble on India\n",
            "   Source: Gizmodo.com ‚≠ê‚≠ê‚≠ê\n",
            "   Published: 2025-07-14\n",
            "   Link: https://gizmodo.com/as-sales-drop-tesla-makes-a-big-gamble-on-india-2000628824\n",
            "\n",
            "2. Thousands pay tribute to veteran Indian communist leader\n",
            "   Source: BBC News ‚≠ê‚≠ê‚≠ê\n",
            "   Published: 2025-07-23\n",
            "   Link: https://www.bbc.com/news/articles/cx209zl0l8no\n",
            "\n",
            "3. Report: Apple's India Manufacturing Dream in Jeopardy Over Exodus of Chinese Workers\n",
            "   Source: MacRumors ‚≠ê‚≠ê‚≠ê\n",
            "   Published: 2025-07-02\n",
            "   Link: https://www.macrumors.com/2025/07/02/apples-india-manufacturing-in-jeopardy/\n",
            "\n",
            "4. Yemen to execute Indian nurse on death row - can she be saved?\n",
            "   Source: BBC News ‚≠ê‚≠ê‚≠ê\n",
            "   Published: 2025-07-09\n",
            "   Link: https://www.bbc.com/news/articles/crrqn0pk5l5o?xtor=AL-72-%5Bpartner%5D-%5Byahoo.north.america%5D-%5Bheadline%5D-%5Bnews%5D-%5Bbizdev%5D-%5Bisapi%5D\n",
            "\n",
            "5. India says it killed militants behind the deadly attack on civilians in Kashmir\n",
            "   Source: NPR ‚≠ê‚≠ê‚≠ê\n",
            "   Published: 2025-07-30\n",
            "   Link: https://www.npr.org/2025/07/30/nx-s1-5484831/india-militants-killed-kashmir\n",
            "\n",
            "\n",
            "What news would you like? January 29, 2025.\n",
            "NewsAPI error: 426 Client Error: Upgrade Required for url: https://newsapi.org/v2/everything?apiKey=6c4b7400256e46379249144ecd9bcb5d&q=January+29%2C+2025.&language=en&sortBy=relevancy&pageSize=10&from=2025-01-29&to=2025-01-29\n",
            "No news found matching your criteria. Try different keywords.\n",
            "\n",
            "What news would you like? jamshedpur, jharkhand news\n",
            "No news found matching your criteria. Try different keywords.\n",
            "\n",
            "What news would you like? flight accident\n",
            "\n",
            "üì∞ Found 5 articles:\n",
            "\n",
            "1. Four foreign nationals died in airport plane crash\n",
            "   Source: BBC News ‚≠ê‚≠ê‚≠ê\n",
            "   Published: 2025-07-14\n",
            "   Link: https://www.bbc.com/news/articles/cz9k2g9j8vno\n",
            "\n",
            "2. Air India crash victim's relative 'can't be at peace' until root cause known\n",
            "   Source: BBC News ‚≠ê‚≠ê‚≠ê\n",
            "   Published: 2025-07-12\n",
            "   Link: https://www.bbc.com/news/articles/c80pmv1leg5o\n",
            "\n",
            "3. The NTSB is set to hold a hearing on the DCA midair collision. Here's what to know\n",
            "   Source: NPR ‚≠ê‚≠ê‚≠ê\n",
            "   Published: 2025-07-30\n",
            "   Link: https://www.npr.org/2025/07/30/nx-s1-5481820/ntsb-dca-army-black-hawk-midair-collision-hearings\n",
            "\n",
            "4. Airlines are inspecting Boeing 787 fuel switches after the first Air India crash report put them in the spotlight\n",
            "   Source: Business Insider ‚≠ê‚≠ê‚≠ê\n",
            "   Published: 2025-07-15\n",
            "   Link: https://www.businessinsider.com/air-india-crash-airlines-check-boeing-787-fuel-switches-2025-7\n",
            "\n",
            "5. Man who jumped from edge of space dies paragliding\n",
            "   Source: BBC News ‚≠ê‚≠ê‚≠ê\n",
            "   Published: 2025-07-17\n",
            "   Link: https://www.bbc.com/news/articles/cx2k7094e8xo\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Configuration\n",
        "NEWS_API_KEY = \"6c4b7400256e46379249144ecd9bcb5d\"  # Your provided key\n",
        "SOURCES = {\n",
        "    \"newsapi\": \"https://newsapi.org/v2\",\n",
        "    \"reuters\": \"https://www.reuters.com\",\n",
        "    \"bbc\": \"https://www.bbc.com/news\",\n",
        "    \"aljazeera\": \"https://www.aljazeera.com\",\n",
        "    \"apnews\": \"https://apnews.com\",\n",
        "    \"flipboard\": \"https://flipboard.com\",\n",
        "    \"yahoo\": \"https://news.yahoo.com\",\n",
        "    \"newsnow\": \"https://www.newsnow.co.uk\",\n",
        "    \"allafrica\": \"https://allafrica.com\",\n",
        "    \"gdelt\": \"https://api.gdeltproject.org/api/v2/doc/doc\"\n",
        "}\n",
        "\n",
        "class NewsAggregator:\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({'User-Agent': 'NewsAgencyBot/1.0'})\n",
        "\n",
        "    def get_news(self, query, country=None, category=None, date_range=None):\n",
        "        \"\"\"Main function to fetch and process news\"\"\"\n",
        "        results = []\n",
        "\n",
        "        # Try NewsAPI first (using your key)\n",
        "        try:\n",
        "            newsapi_results = self._fetch_newsapi(query, country, category, date_range)\n",
        "            results.extend(newsapi_results)\n",
        "        except Exception as e:\n",
        "            print(f\"NewsAPI error: {str(e)}\")\n",
        "\n",
        "        # Fallback to other sources if needed\n",
        "        if len(results) < 3:\n",
        "            try:\n",
        "                google_results = self._fetch_google_news(query, country)\n",
        "                results.extend(google_results)\n",
        "            except Exception as e:\n",
        "                print(f\"Google News error: {str(e)}\")\n",
        "\n",
        "        # Remove duplicates and prioritize\n",
        "        unique_results = self._deduplicate(results)\n",
        "        prioritized = self._prioritize_sources(unique_results, category)\n",
        "\n",
        "        return prioritized[:5]  # Return top 5 results\n",
        "\n",
        "    def _fetch_newsapi(self, query, country, category, date_range):\n",
        "        \"\"\"Fetch from NewsAPI using your key\"\"\"\n",
        "        params = {\n",
        "            'apiKey': NEWS_API_KEY,\n",
        "            'q': query,\n",
        "            'language': 'en',\n",
        "            'sortBy': 'relevancy',\n",
        "            'pageSize': 10\n",
        "        }\n",
        "\n",
        "        if country:\n",
        "            params['country'] = self._country_code(country)\n",
        "        if category:\n",
        "            params['category'] = category.lower()\n",
        "        if date_range:\n",
        "            params['from'] = self._format_date(date_range[0])\n",
        "            params['to'] = self._format_date(date_range[1])\n",
        "\n",
        "        response = self.session.get(f\"{SOURCES['newsapi']}/everything\", params=params)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        articles = []\n",
        "        for item in response.json().get('articles', []):\n",
        "            articles.append({\n",
        "                'title': item['title'],\n",
        "                'url': item['url'],\n",
        "                'source': item['source']['name'],\n",
        "                'published': item['publishedAt'][:10],\n",
        "                'credibility': self._source_credibility(item['source']['name'])\n",
        "            })\n",
        "        return articles\n",
        "\n",
        "    def _fetch_google_news(self, query, country):\n",
        "        \"\"\"Fallback to Google News scraping\"\"\"\n",
        "        params = {\n",
        "            'q': query,\n",
        "            'hl': 'en',\n",
        "            'gl': self._country_code(country) if country else 'US',\n",
        "            'ceid': f\"{self._country_code(country) if country else 'US'}:en\"\n",
        "        }\n",
        "\n",
        "        response = self.session.get(\"https://news.google.com/rss/search\", params=params)\n",
        "        # Note: In production, use proper RSS parsing\n",
        "        # This is a simplified version\n",
        "        return self._parse_rss(response.text)\n",
        "\n",
        "    def _parse_rss(self, rss_content):\n",
        "        \"\"\"Parse RSS feed (simplified version)\"\"\"\n",
        "        # In production, use feedparser or similar library\n",
        "        articles = []\n",
        "        # RSS parsing logic here\n",
        "        return articles\n",
        "\n",
        "    def _deduplicate(self, articles):\n",
        "        \"\"\"Remove duplicate articles\"\"\"\n",
        "        seen = set()\n",
        "        unique = []\n",
        "        for article in articles:\n",
        "            # Create a unique key from title and source\n",
        "            key = (article['title'][:30], article['source'])\n",
        "            if key not in seen:\n",
        "                seen.add(key)\n",
        "                unique.append(article)\n",
        "        return unique\n",
        "\n",
        "    def _prioritize_sources(self, articles, category):\n",
        "        \"\"\"Prioritize sources based on category\"\"\"\n",
        "        priority_map = {\n",
        "            'politics': ['Reuters', 'BBC', 'AP News', 'The Guardian'],\n",
        "            'business': ['Reuters', 'Bloomberg', 'Financial Times'],\n",
        "            'technology': ['TechCrunch', 'Wired', 'Ars Technica'],\n",
        "            'sports': ['ESPN', 'BBC Sport', 'Sky Sports'],\n",
        "            'health': ['WHO', 'CDC', 'WebMD', 'Mayo Clinic'],\n",
        "            'science': ['Nature', 'Science', 'New Scientist'],\n",
        "            'entertainment': ['Variety', 'Hollywood Reporter', 'Entertainment Weekly']\n",
        "        }\n",
        "\n",
        "        preferred = priority_map.get(category, [])\n",
        "        return sorted(\n",
        "            articles,\n",
        "            key=lambda x: (preferred.index(x['source']) if x['source'] in preferred else 999, -x['credibility'])\n",
        "        )\n",
        "\n",
        "    def _source_credibility(self, source_name):\n",
        "        \"\"\"Assign credibility score (1-5)\"\"\"\n",
        "        credibility_scores = {\n",
        "            'Reuters': 5, 'BBC': 5, 'AP News': 5, 'Al Jazeera': 4,\n",
        "            'The Guardian': 4, 'The New York Times': 4, 'The Washington Post': 4,\n",
        "            'CNN': 3, 'Fox News': 2, 'Yahoo News': 3\n",
        "        }\n",
        "        return credibility_scores.get(source_name, 3)\n",
        "\n",
        "    def _country_code(self, country_name):\n",
        "        \"\"\"Convert country name to ISO code\"\"\"\n",
        "        country_map = {\n",
        "            'united states': 'us', 'uk': 'gb', 'great britain': 'gb',\n",
        "            'germany': 'de', 'france': 'fr', 'japan': 'jp',\n",
        "            'india': 'in', 'china': 'cn', 'canada': 'ca',\n",
        "            'australia': 'au', 'brazil': 'br', 'russia': 'ru'\n",
        "        }\n",
        "        return country_map.get(country_name.lower(), 'us')\n",
        "\n",
        "    def _format_date(self, date_input):\n",
        "        \"\"\"Convert various date formats to YYYY-MM-DD\"\"\"\n",
        "        if isinstance(date_input, datetime):\n",
        "            return date_input.strftime('%Y-%m-%d')\n",
        "\n",
        "        if date_input.lower() == 'today':\n",
        "            return datetime.now().strftime('%Y-%m-%d')\n",
        "        elif date_input.lower() == 'yesterday':\n",
        "            return (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "        elif 'last week' in date_input.lower():\n",
        "            return (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
        "        elif re.match(r'\\d{4}-\\d{2}-\\d{2}', date_input):\n",
        "            return date_input\n",
        "        else:\n",
        "            # Try to parse other formats\n",
        "            try:\n",
        "                return datetime.strptime(date_input, '%B %d, %Y').strftime('%Y-%m-%d')\n",
        "            except:\n",
        "                return datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "# Chatbot Interface\n",
        "def news_chatbot():\n",
        "    aggregator = NewsAggregator()\n",
        "\n",
        "    print(\"üåç Global News Aggregator - Type 'exit' to quit\")\n",
        "    print(\"Examples: 'politics news from Germany', 'natural disasters last week', 'vehicle industry news'\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nWhat news would you like? \").strip()\n",
        "\n",
        "        if user_input.lower() in ['exit', 'quit']:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Parse user query\n",
        "        query_parts = {\n",
        "            'query': '',\n",
        "            'country': None,\n",
        "            'category': None,\n",
        "            'date_range': None\n",
        "        }\n",
        "\n",
        "        # Extract country\n",
        "        country_match = re.search(r'from (\\w+)', user_input, re.IGNORECASE)\n",
        "        if country_match:\n",
        "            query_parts['country'] = country_match.group(1)\n",
        "\n",
        "        # Extract category\n",
        "        categories = ['politics', 'business', 'technology', 'sports', 'health', 'science', 'entertainment', 'vehicle']\n",
        "        for cat in categories:\n",
        "            if cat in user_input.lower():\n",
        "                query_parts['category'] = cat\n",
        "                query_parts['query'] = user_input.lower().replace(cat, '').strip()\n",
        "                break\n",
        "\n",
        "        # Extract date\n",
        "        date_match = re.search(r'(today|yesterday|last week|\\d{4}-\\d{2}-\\d{2}|[A-Za-z]+ \\d{1,2}, \\d{4})', user_input, re.IGNORECASE)\n",
        "        if date_match:\n",
        "            date_str = date_match.group(1)\n",
        "            query_parts['date_range'] = (date_str, date_str)\n",
        "\n",
        "        if not query_parts['query']:\n",
        "            query_parts['query'] = user_input\n",
        "\n",
        "        # Get news\n",
        "        results = aggregator.get_news(**query_parts)\n",
        "\n",
        "        # Display results\n",
        "        if not results:\n",
        "            print(\"No news found matching your criteria. Try different keywords.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nüì∞ Found {len(results)} articles:\\n\")\n",
        "        for i, article in enumerate(results, 1):\n",
        "            print(f\"{i}. {article['title']}\")\n",
        "            print(f\"   Source: {article['source']} {'‚≠ê' * article['credibility']}\")\n",
        "            print(f\"   Published: {article['published']}\")\n",
        "            print(f\"   Link: {article['url']}\\n\")\n",
        "\n",
        "# Run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    news_chatbot()"
      ]
    }
  ]
}